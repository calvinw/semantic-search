{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Semantic Search of HM Dresses"
      ],
      "id": "50077507-5183-452d-b380-f2cfca5ea5a5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import io \n",
        "import sys\n",
        "from contextlib import contextmanager\n",
        "import warnings\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = 'calvinw'\n",
        "os.environ['KAGGLE_KEY'] = 'b9096f0f988cca2a5d0402a878e8607a'\n",
        "\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "@contextmanager\n",
        "def suppress_all_output():\n",
        "    \"\"\"\n",
        "    A context manager that suppresses all output including stdout, stderr, and warnings.\n",
        "    \"\"\"\n",
        "    # Save the original stdout, stderr, and warnings settings\n",
        "    old_stdout = sys.stdout\n",
        "    old_stderr = sys.stderr\n",
        "    warnings.filterwarnings('ignore')\n",
        "    \n",
        "    # Create a dummy io stream\n",
        "    dummy = io.StringIO()\n",
        "    \n",
        "    try:\n",
        "        # Redirect all output to the dummy stream\n",
        "        sys.stdout = dummy\n",
        "        sys.stderr = dummy\n",
        "        yield\n",
        "    finally:\n",
        "        # Restore original settings\n",
        "        sys.stdout = old_stdout\n",
        "        sys.stderr = old_stderr\n",
        "        warnings.resetwarnings()"
      ],
      "id": "8e7be82d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import time\n",
        "from collections import Counter\n",
        "from io import StringIO\n",
        "from io import BytesIO\n",
        "from typing import List, Tuple\n",
        "import requests\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Markdown"
      ],
      "id": "0df68ad7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_specific_image(article_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Download a specific image file from the H&M dataset.\n",
        "    \n",
        "    Parameters:\n",
        "    article_id: The article ID (will be padded to 10 digits)\n",
        "    \n",
        "    Returns:\n",
        "    Path to the downloaded file\n",
        "    \"\"\"\n",
        "    # Pad the article ID to 10 digits\n",
        "    padded_id = f\"{int(article_id):010d}\"\n",
        "    # Get the subfolder name (first 3 digits of padded article ID)\n",
        "    subfolder = padded_id[:3]\n",
        "    \n",
        "    # Construct the path within the dataset\n",
        "    image_path = f\"images/{subfolder}/{padded_id}.jpg\"\n",
        "\n",
        "    with suppress_all_output(): \n",
        "        api.competition_download_file('h-and-m-personalized-fashion-recommendations', image_path)\n",
        "\n",
        "    return f\"{padded_id}.jpg\""
      ],
      "id": "45c2da95"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ProductSearcher:\n",
        "    def __init__(self, embeddings_url: str = \"https://github.com/calvinw/semantic-search/raw/refs/heads/main/product_embeddings.npz\"):\n",
        "        \"\"\"Initialize the searcher with embeddings from GitHub URL.\"\"\"\n",
        "        print(\"Downloading embeddings file from GitHub...\")\n",
        "        try:\n",
        "            response = requests.get(embeddings_url)\n",
        "            response.raise_for_status()\n",
        "            \n",
        "            # Load the embeddings from the downloaded content\n",
        "            print(\"Loading embeddings and model...\")\n",
        "            self.data = np.load(BytesIO(response.content), allow_pickle=True)\n",
        "            self.embeddings = self.data['embeddings']\n",
        "            self.product_names = self.data['product_names']\n",
        "            self.embedding_strings = self.data['embedding_strings']\n",
        "            self.product_codes = self.data['product_codes']\n",
        "            self.article_ids_str = self.data['article_ids_str']\n",
        "            \n",
        "            # Load the model\n",
        "            print(\"Loading sentence transformer model...\")\n",
        "            self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            print(\"Model loaded successfully!\")\n",
        "            \n",
        "            print(f\"Loaded {len(self.embeddings)} products\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error in initialization: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def get_article_image(self, article_id: str) -> Image.Image:\n",
        "        \"\"\"Load image for a given article ID.\"\"\"\n",
        "\n",
        "        with suppress_all_output(): \n",
        "            download_specific_image(article_id)\n",
        "\n",
        "        padded_id = f\"{int(article_id):010d}\"\n",
        "        image_path = f\"{padded_id}.jpg\" \n",
        "        \n",
        "        try:\n",
        "            return Image.open(image_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load image for article ID {article_id} (padded: {padded_id}): {e}\")\n",
        "            return None\n",
        "    \n",
        "    def search(self, query: str, top_k: int = 4) -> List[Tuple[int, float]]:\n",
        "        \"\"\"Search for products using a text query.\"\"\"\n",
        "        query_embedding = self.model.encode([query])[0]\n",
        "        \n",
        "        similarities = np.dot(self.embeddings, query_embedding) / (\n",
        "            np.linalg.norm(self.embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
        "        )\n",
        "        \n",
        "        top_idx = np.argsort(similarities)[::-1][:top_k]\n",
        "        return [(idx, similarities[idx]) for idx in top_idx]\n",
        "    \n",
        "    def print_search_results(self, query: str, top_k: int = 3):\n",
        "        \"\"\"Perform search and print results with images in a readable format using Markdown.\"\"\"\n",
        "        # Display header\n",
        "        display(Markdown(f\"\"\"\n",
        "# Search Results\n",
        "## Query: \"{query}\"\n",
        "\"\"\"))\n",
        "        \n",
        "        results = self.search(query, top_k)\n",
        "        images_to_display = []\n",
        "        titles = []\n",
        "        \n",
        "        # Display results in Markdown format\n",
        "        for idx, score in results:\n",
        "            markdown_result = f\"\"\"\n",
        "### Match Score: {score:.3f}\n",
        "\n",
        "**Product Name:** {self.product_names[idx]}  \n",
        "**Product Code:** `{self.product_codes[idx]}`  \n",
        "**Article IDs:** `{self.article_ids_str[idx]}`\n",
        "\n",
        "**Description:**  \n",
        "{self.embedding_strings[idx]}\n",
        "\n",
        "---\n",
        "\"\"\"\n",
        "            display(Markdown(markdown_result))\n",
        "            \n",
        "            # Collect image and title information\n",
        "            first_article_id = self.article_ids_str[idx].split(',')[0]\n",
        "            with suppress_all_output(): \n",
        "                img = self.get_article_image(first_article_id)\n",
        "\n",
        "            if img is not None:\n",
        "                images_to_display.append(img)\n",
        "                titles.append(f\"{self.product_names[idx]}\\nArticle ID: {first_article_id}\")\n",
        "        \n",
        "        # Display images\n",
        "        if images_to_display:\n",
        "            fig = plt.figure(figsize=(12, 8))\n",
        "            for i, (img, title) in enumerate(zip(images_to_display, titles), 1):\n",
        "                plt.subplot(1, len(images_to_display), i)\n",
        "                plt.imshow(img)\n",
        "                plt.title(title, wrap=True)\n",
        "                plt.axis('off')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            display(plt.gcf())\n",
        "            plt.close()\n",
        "\n",
        "searcher = ProductSearcher()"
      ],
      "id": "92956abf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "searcher.print_search_results(\"Socks for holiday\")\n",
        "searcher.print_search_results(\"A party dress for office party\")"
      ],
      "id": "cc541128"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}