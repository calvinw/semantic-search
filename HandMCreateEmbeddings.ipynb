{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# H and M Create Embeddings"
      ],
      "id": "f044573c-0971-4816-bd2b-9d7266692f43"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path\n",
        "import time\n",
        "from collections import Counter\n",
        "import requests\n",
        "from io import StringIO\n",
        "from typing import List, Tuple\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_enhanced_descriptions(df):\n",
        "    \"\"\"\n",
        "    Create enhanced product descriptions with grouped attributes.\n",
        "    Returns DataFrame with unique products and their enhanced descriptions.\n",
        "    \"\"\"\n",
        "    print(\"\\nGrouping products and creating enhanced descriptions...\")\n",
        "    \n",
        "    # Group by product code\n",
        "    product_groups = df.groupby('product_code').agg({\n",
        "        'prod_name': 'first',\n",
        "        'product_type_name': 'first',\n",
        "        'detail_desc': 'first',\n",
        "        'colour_group_name': lambda x: sorted(list(set(x))),\n",
        "        'graphical_appearance_name': lambda x: sorted(list(set(x))),\n",
        "        'article_id': list  # Keep all article IDs for this product\n",
        "    }).reset_index()\n",
        "    \n",
        "    # Create enhanced descriptions with simple progress tracking\n",
        "    results = []\n",
        "    total_products = len(product_groups)\n",
        "    print(f\"Processing {total_products} products...\")\n",
        "    \n",
        "    for idx, row in product_groups.iterrows():\n",
        "        if idx % 1000 == 0:  # Print progress every 1000 items\n",
        "            print(f\"Progress: {idx}/{total_products} products processed ({(idx/total_products*100):.1f}%)\")\n",
        "            \n",
        "        colors = f\"[Colors: {', '.join(row['colour_group_name'])}]\"\n",
        "        patterns = f\"[Patterns: {', '.join(row['graphical_appearance_name'])}]\"\n",
        "        \n",
        "        #enhanced_desc = (f\"{row['prod_name']} | {row['product_type_name']} | \"\n",
        "        #                f\"{colors} {patterns} | {row['detail_desc']}\")\n",
        "        enhanced_desc = (f\"{row['product_type_name']} | \"\n",
        "                         f\"{colors} {patterns} | {row['detail_desc']}\")\n",
        "        \n",
        "        results.append({\n",
        "            'product_code': row['product_code'],\n",
        "            'product_name': row['prod_name'],\n",
        "            'article_ids': row['article_id'],\n",
        "            'num_variants': len(row['colour_group_name']),\n",
        "            'colors': row['colour_group_name'],\n",
        "            'patterns': row['graphical_appearance_name'],\n",
        "            'embedding_string': enhanced_desc\n",
        "        })\n",
        "    \n",
        "    print(f\"Completed processing all {total_products} products\")\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "def batch_encode(model, texts, batch_size=32):\n",
        "    \"\"\"\n",
        "    Encode texts in batches with simple progress tracking.\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    total_batches = (len(texts) + batch_size - 1) // batch_size\n",
        "    print(f\"\\nCreating embeddings for {len(texts)} texts in {total_batches} batches...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_num = i // batch_size + 1\n",
        "        if batch_num % 10 == 0:  # Print progress every 10 batches\n",
        "            elapsed = time.time() - start_time\n",
        "            avg_time_per_batch = elapsed / batch_num\n",
        "            remaining_batches = total_batches - batch_num\n",
        "            est_remaining = remaining_batches * avg_time_per_batch\n",
        "            \n",
        "            print(f\"Batch {batch_num}/{total_batches} \"\n",
        "                  f\"({(batch_num/total_batches*100):.1f}%) - \"\n",
        "                  f\"Est. remaining time: {est_remaining/60:.1f} minutes\")\n",
        "        \n",
        "        batch = texts[i:i + batch_size]\n",
        "        batch_embeddings = model.encode(batch, show_progress_bar=False)\n",
        "        embeddings.append(batch_embeddings)\n",
        "    \n",
        "    print(\"\\nEmbedding creation completed!\")\n",
        "    return np.vstack(embeddings)\n",
        "    \n",
        "def print_dataset_statistics(df, enhanced_df):\n",
        "    \"\"\"Print comprehensive statistics about the dataset and embeddings.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"DATASET STATISTICS\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    print(\"\\nBasic Statistics:\")\n",
        "    print(f\"Total number of articles: {len(df)}\")\n",
        "    print(f\"Unique products: {len(enhanced_df)}\")\n",
        "    print(f\"Average variants per product: {enhanced_df['num_variants'].mean():.2f}\")\n",
        "    \n",
        "    print(\"\\nVariant Distribution:\")\n",
        "    variant_counts = enhanced_df['num_variants'].value_counts().sort_index()\n",
        "    for variants, count in variant_counts.items():\n",
        "        print(f\"Products with {variants} variants: {count}\")\n",
        "    \n",
        "    print(\"\\nTop 10 Products with Most Variants:\")\n",
        "    most_variants = enhanced_df.nlargest(10, 'num_variants')\n",
        "    for _, row in most_variants.iterrows():\n",
        "        print(f\"{row['product_name']}: {row['num_variants']} variants\")\n",
        "    \n",
        "    # Analyze colors\n",
        "    all_colors = [color for colors in enhanced_df['colors'] for color in colors]\n",
        "    print(\"\\nTop 10 Most Common Colors:\")\n",
        "    for color, count in Counter(all_colors).most_common(10):\n",
        "        print(f\"{color}: {count} products\")\n",
        "    \n",
        "    # Analyze patterns\n",
        "    all_patterns = [pattern for patterns in enhanced_df['patterns'] for pattern in patterns]\n",
        "    print(\"\\nPattern Distribution:\")\n",
        "    for pattern, count in Counter(all_patterns).most_common():\n",
        "        print(f\"{pattern}: {count} products\")\n",
        "    \n",
        "    # Analyze string lengths\n",
        "    string_lengths = enhanced_df['embedding_string'].str.len()\n",
        "    print(\"\\nEmbedding String Length Statistics:\")\n",
        "    print(f\"Average length: {string_lengths.mean():.1f} characters\")\n",
        "    print(f\"Maximum length: {string_lengths.max()} characters\")\n",
        "    print(f\"Minimum length: {string_lengths.min()} characters\")\n",
        "\n",
        "\n",
        "def save_embeddings(embeddings, product_data, filepath):\n",
        "    \"\"\"\n",
        "    Save embeddings and related data as a compressed NPZ file.\n",
        "    Handles lists of different lengths properly.\n",
        "    \"\"\"\n",
        "    if not filepath.endswith('.npz'):\n",
        "        filepath = f\"{filepath}.npz\"\n",
        "    \n",
        "    # Convert article_ids to a string representation for each product\n",
        "    article_ids_str = [','.join(map(str, ids)) for ids in product_data['article_ids']]\n",
        "    \n",
        "    # Prepare metadata\n",
        "    metadata = {\n",
        "        'num_products': len(product_data),\n",
        "        'embedding_dim': embeddings.shape[1],\n",
        "        'date_created': np.datetime64('now').astype(str),\n",
        "        'model_used': 'all-MiniLM-L6-v2',\n",
        "        'description': 'Product embeddings with grouped color variants'\n",
        "    }\n",
        "    \n",
        "    # Save compressed npz file\n",
        "    np.savez_compressed(\n",
        "        filepath,\n",
        "        embeddings=embeddings,\n",
        "        product_codes=product_data['product_code'].values,\n",
        "        article_ids_str=article_ids_str,  # Store as comma-separated strings\n",
        "        product_names=product_data['product_name'].values,\n",
        "        embedding_strings=product_data['embedding_string'].values,\n",
        "        metadata=metadata\n",
        "    )\n",
        "    \n",
        "    # Print file info\n",
        "    file_size_mb = Path(filepath).stat().st_size / (1024 * 1024)\n",
        "    print(f\"\\nSaved embeddings file:\")\n",
        "    print(f\"Path: {filepath}\")\n",
        "    print(f\"Size: {file_size_mb:.2f} MB\")\n",
        "    print(f\"Products: {len(product_data)}\")\n",
        "    print(f\"Embedding dimensions: {embeddings.shape[1]}\")\n",
        "    \n",
        "    # Print first few products as examples\n",
        "    print(\"\\nFirst few products saved:\")\n",
        "    for i in range(min(3, len(product_data))):\n",
        "        print(f\"\\nProduct: {product_data['product_name'].iloc[i]}\")\n",
        "        print(f\"Article IDs: {article_ids_str[i]}\")\n",
        "        print(f\"Embedding string length: {len(product_data['embedding_string'].iloc[i])}\")\n",
        "\n",
        "def create_embeddings():\n",
        "    \n",
        "    start_time = time.time()\n",
        " \n",
        "    url = \"https://github.com/calvinw/semantic-search/raw/refs/heads/main/articles.csv\"\n",
        "    df = pd.read_csv(url)\n",
        "\n",
        "    enhanced_df = create_enhanced_descriptions(df)\n",
        "\n",
        "    # Add this section to print example embedding strings\n",
        "    print(\"\\nExample embedding strings that will be embedded:\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    for i in range(5):  # Show first 5 examples\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(enhanced_df['embedding_string'].iloc[i])\n",
        "        print(\"-\"*80)\n",
        "\n",
        "    print_dataset_statistics(df, enhanced_df)\n",
        "    \n",
        "    print(\"\\nInitializing embedding model...\")\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    \n",
        "    # Create embeddings with custom batching and progress tracking\n",
        "    embeddings = batch_encode(\n",
        "        model, \n",
        "        enhanced_df['embedding_string'].tolist(),\n",
        "        batch_size=32\n",
        "    )\n",
        "    \n",
        "    save_embeddings(embeddings, enhanced_df, \"product_embeddings\")\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"\\nTotal processing time: {elapsed_time:.1f} seconds\")"
      ],
      "id": "09c84b2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_embeddings()"
      ],
      "id": "28b3d23c"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    }
  }
}